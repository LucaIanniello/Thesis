{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLCCM5Ev7iDF"
      },
      "source": [
        "# Demo of the MAGICAL benchmark suite for robust IL\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qxcv/magical/blob/pyglet1.5/demo-notebook.ipynb)\n",
        "\n",
        "This self-contained Colab notebook shows how to train a simple imitation learning agent on MAGICAL using behavioural cloning (BC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1my5TdGlh-O"
      },
      "source": [
        "## Setup code\n",
        "\n",
        "This does a few things:\n",
        "\n",
        "- Installs `xvfb` so that MAGICAL has access to an X server.\n",
        "- Installs all the Python dependencies for MAGICAL, as well as a copy of the [imitation](https://github.com/HumanCompatibleAI/imitation) library.\n",
        "- Downloads demonstrations for MAGICAL.\n",
        "\n",
        "These setup steps will take a few minutes complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Vhtm7mY7iDG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu92\n",
            "  Using cached https://download.pytorch.org/whl/cu92/torch-1.6.0%2Bcu92-cp38-cp38-linux_x86_64.whl (552.8 MB)\n",
            "Collecting torchvision==0.7.0+cu92\n",
            "  Using cached https://download.pytorch.org/whl/cu92/torchvision-0.7.0%2Bcu92-cp38-cp38-linux_x86_64.whl (5.8 MB)\n",
            "Requirement already satisfied: future in /home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages (from torch==1.6.0+cu92) (1.0.0)\n",
            "Requirement already satisfied: numpy in /home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages (from torch==1.6.0+cu92) (1.24.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages (from torchvision==0.7.0+cu92) (10.4.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.6.0+cu92 torchvision-0.7.0+cu92\n",
            "Collecting imitation\n",
            "  Cloning git://github.com/HumanCompatibleAI/imitation (to revision 556f5d8384d99fa5ab8bc54a9828887a2db8c669) to /tmp/pip-install-dfcazur1/imitation_e4ed2ca7163e4d1296e00a4927bd6155\n",
            "  Running command git clone --filter=blob:none --quiet git://github.com/HumanCompatibleAI/imitation /tmp/pip-install-dfcazur1/imitation_e4ed2ca7163e4d1296e00a4927bd6155\n",
            "  fatal: unable to connect to github.com:\n",
            "  github.com[0: 140.82.121.3]: errno=Connection timed out\n",
            "\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet git:\u001b[0m\u001b[32m/\u001b[0m\u001b[32m/github.com/HumanCompatibleAI/\u001b[0m\u001b[32mimitation\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/pip-install-dfcazur1/\u001b[0m\u001b[32mimitation_e4ed2ca7163e4d1296e00a4927bd6155\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet git:\u001b[0m\u001b[32m/\u001b[0m\u001b[32m/github.com/HumanCompatibleAI/\u001b[0m\u001b[32mimitation\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/pip-install-dfcazur1/\u001b[0m\u001b[32mimitation_e4ed2ca7163e4d1296e00a4927bd6155\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'xvfbwrapper'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip install  \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmagical-il\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscikit-video~=1.1.11\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxvfbwrapper~=0.2.9\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit+git://github.com/HumanCompatibleAI/imitation@556f5d8384d99fa5ab8bc54a9828887a2db8c669#egg=imitation\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvdisplay\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# start a virtual X display for MAGICAL rendering\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxvfbwrapper\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     vdisplay \u001b[38;5;241m=\u001b[39m xvfbwrapper\u001b[38;5;241m.\u001b[39mXvfb()\n\u001b[1;32m     14\u001b[0m     vdisplay\u001b[38;5;241m.\u001b[39mstart()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xvfbwrapper'"
          ]
        }
      ],
      "source": [
        "# Install MAGICAL, Xvfb, and a prerelease version of the 'imitation' library (https://github.com/HumanCompatibleAI/imitation)\n",
        "#\n",
        "# The pip install commands can give errors of the form \"package W requires version X of package Y, but you'll have\n",
        "# version Z which is incompatible\". You can safely ignore those errors; I suspect they are conflicts in the default\n",
        "# Colab environment.\n",
        "!pip uninstall -qy torch torchvision\n",
        "!pip install torch==1.6.0+cu92 torchvision==0.7.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install  'magical-il' 'scikit-video~=1.1.11' 'xvfbwrapper~=0.2.9' 'git+git://github.com/HumanCompatibleAI/imitation@556f5d8384d99fa5ab8bc54a9828887a2db8c669#egg=imitation'\n",
        "if 'vdisplay' not in globals():\n",
        "    # start a virtual X display for MAGICAL rendering\n",
        "    import xvfbwrapper\n",
        "    vdisplay = xvfbwrapper.Xvfb()\n",
        "\n",
        "    vdisplay.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ie_RQjct7iDH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages/imitation/algorithms/bc.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  import tqdm.autonotebook as tqdm\n",
            "/home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import gym\n",
        "from imitation.algorithms.bc import BC\n",
        "import imitation.augment as il_augment\n",
        "from imitation.data import rollout\n",
        "import imitation.data.types as il_types\n",
        "from imitation.util.util import make_vec_env\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import skvideo.io as vidio\n",
        "import stable_baselines3.common.policies as sb3_pols\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as th_data\n",
        "\n",
        "import magical\n",
        "from magical.evaluation import EvaluationProtocol\n",
        "\n",
        "magical.register_envs()\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "# download trajectories\n",
        "#magical.try_download_demos(dest=\"demos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PcEkoJI9_gh-"
      },
      "outputs": [],
      "source": [
        "class MAGICALNet(nn.Module):\n",
        "    \"\"\"Custom CNN for MAGICAL policies.\"\"\"\n",
        "    def __init__(self, observation_space, out_chans=256, width=2):\n",
        "        super().__init__()\n",
        "        w = width\n",
        "        def conv_block(i, o, k, s, p, b=False):\n",
        "            return [\n",
        "                # batch norm has its own bias, so don't add one to conv layers by default\n",
        "                nn.Conv2d(i, o, kernel_size=k, stride=s, padding=p, bias=b,\n",
        "                          padding_mode='zeros'),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(o)\n",
        "            ]\n",
        "        conv_layers = [\n",
        "            *conv_block(i=observation_space.shape[0], o=32*w, k=5, s=1, p=2, b=True),\n",
        "            *conv_block(i=32*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "            *conv_block(i=64*w, o=64*w, k=3, s=2, p=1),\n",
        "        ]\n",
        "        # final FC layer to make feature maps the right size\n",
        "        test_tensor = torch.zeros((1,) + observation_space.shape)\n",
        "        for layer in conv_layers:\n",
        "            test_tensor = layer(test_tensor)\n",
        "        fc_in_size = np.prod(test_tensor.shape)\n",
        "        reduction_layers = [\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(fc_in_size, out_chans),\n",
        "            # Stable Baselines will add extra affine layer on top of this reLU\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        self.features_dim = out_chans\n",
        "        all_layers = [*conv_layers, *reduction_layers]\n",
        "        self.feature_generator = nn.Sequential(*all_layers)\n",
        "\n",
        "    def forward(self, x, traj_info=None):\n",
        "        return self.feature_generator(x)\n",
        "\n",
        "class ImitationEvaluationProtocol(EvaluationProtocol):\n",
        "    \"\"\"EvaluationProtocol is an abstract base class which is able to evaluate a MAGICAL policy on a set of test\n",
        "    environments & appropriate calculate confidence intervals & other statistics for the mean score in each environment.\n",
        "    Concrete instances of EvaluationProtocol must provide their own method for generating trajectories, and also provide\n",
        "    a name for the resulting evaluation data (which will be written into the Pandas dataframe used to compute\n",
        "    statistics).\n",
        "\n",
        "    This subclass of EvaluationProtocol uses the `imitation` library to generate the require trajectories.\"\"\"\n",
        "    def __init__(self, policy, run_description, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.policy = policy\n",
        "        self.run_description = run_description\n",
        "\n",
        "    @property\n",
        "    def run_id(self):\n",
        "        # simple string describing this run\n",
        "        return self.run_description\n",
        "\n",
        "    def obtain_scores(self, env_name):\n",
        "        print(f\"Sampling {self.n_rollouts} trajectories on {env_name}\")\n",
        "        vec_env = make_vec_env(env_name=env_name, n_envs=min(25, self.n_rollouts))  # sample in parallel\n",
        "        trajectories = rollout.generate_trajectories(self.policy,\n",
        "                                                     vec_env,\n",
        "                                                     sample_until=rollout.min_episodes(self.n_rollouts),\n",
        "                                                     deterministic_policy=False)\n",
        "        # the MAGICAL score is passed through the final info dict in each trajectory\n",
        "        scores = [traj.infos[-1]['eval_score'] for traj in trajectories]\n",
        "        return scores\n",
        "\n",
        "def create_policy_video(policy, demo_env_name, traj_per_env=1, fps=24):\n",
        "    \"\"\"Create a video showing policy performance on the demo environment and all test environments.\"\"\"\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".mp4\") as fp:\n",
        "        writer = vidio.FFmpegWriter(fp.name, outputdict={'-r': str(fps), '-vcodec': 'libx264', '-pix_fmt': 'yuv420p'})\n",
        "\n",
        "        # for both demo environment + test environments, we append `traj_per_env` demos to the video\n",
        "        env_name_list = (demo_env_name, ) + magical.DEMO_ENVS_TO_TEST_ENVS_MAP[demo_env_name]\n",
        "        for env_name in env_name_list:\n",
        "            vec_env = make_vec_env(env_name=env_name, n_envs=min(traj_per_env, 25))\n",
        "            trajectories = rollout.generate_trajectories(policy, vec_env,\n",
        "                                                        sample_until=rollout.min_episodes(traj_per_env),)\n",
        "            vec_env.close()\n",
        "            for traj in trajectories:\n",
        "                for obs in traj.obs:\n",
        "                    # each observation is a frame stack; we write only the last (RGB) frame, transposed to be channels-last\n",
        "                    rgb_frame = np.transpose(obs[-3:], (1, 2, 0))\n",
        "                    vid_h, vid_w = rgb_frame.shape[:2]\n",
        "                    writer.writeFrame(rgb_frame)\n",
        "\n",
        "        # finish writing video\n",
        "        writer.close()\n",
        "\n",
        "        # now convert video to base64 so we can generate a <video> tag that works with the notebook\n",
        "        vid_base64 = base64.b64encode(fp.read()).decode('utf-8')\n",
        "        print('Video size (MB):', len(vid_base64) / 1e6)\n",
        "        html_string = f\"\"\"<video width=\"{vid_w}\" height=\"{vid_h}\" muted controls loop autoplay>\n",
        "            <source src=\"data:video/mp4;base64,{vid_base64}\" type=\"video/mp4\">\n",
        "            No &lt;video&gt; tag support :(\n",
        "        </video>\"\"\"\n",
        "        return display.HTML(data=html_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD3zdcLLlt1a"
      },
      "source": [
        "## Running MAGICAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.02MiB downloaded\n",
            "10.02MiB downloaded\n",
            "20.03MiB downloaded\n",
            "30.02MiB downloaded\n",
            "40.01MiB downloaded\n",
            "50.01MiB downloaded\n",
            "60.02MiB downloaded\n",
            "70.03MiB downloaded\n",
            "80.00MiB downloaded\n",
            "90.02MiB downloaded\n",
            "100.03MiB downloaded\n",
            "110.02MiB downloaded\n",
            "120.01MiB downloaded\n",
            "130.02MiB downloaded\n",
            "140.01MiB downloaded\n",
            "150.00MiB downloaded\n",
            "160.00MiB downloaded\n",
            "170.01MiB downloaded\n",
            "180.03MiB downloaded\n",
            "190.01MiB downloaded\n",
            "200.03MiB downloaded\n",
            "210.02MiB downloaded\n",
            "220.02MiB downloaded\n"
          ]
        }
      ],
      "source": [
        "import magical\n",
        "magical.try_download_demos(dest=\"demos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1hfHaZG67iDH"
      },
      "outputs": [],
      "source": [
        "env_ident = 'MoveToCorner'\n",
        "preproc_name = 'LoResCHW4E'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E-knOWB17iDH"
      },
      "outputs": [],
      "source": [
        "demo_paths_by_env = {\n",
        "    'MoveToCorner': glob.glob('demos/move-to-corner/demo-*.pkl.gz'),\n",
        "}\n",
        "demo_paths = demo_paths_by_env[env_ident]\n",
        "# Gym env name with preprocessor\n",
        "env_name = f'{env_ident}-Demo-{preproc_name}-v0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eHSVWkb87iDI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading chipmunk for Linux (64bit) [/home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages/pymunk/libchipmunk.so]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MESA: error: ZINK: failed to choose pdev\n",
            "glx: failed to create drisw screen\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(env_name)\n",
        "demo_dicts = magical.load_demos(demo_paths[:10])\n",
        "demo_trajs = []\n",
        "orig_env_name = None  # we will read this from the demos dicts\n",
        "for demo_dict in demo_dicts:\n",
        "    # each demo dict has keys ['trajectory', 'score', 'env_name']\n",
        "    # (trajectory contains the actual data, and score is generally 1.0 for demonstrations)\n",
        "    orig_env_name = demo_dict['env_name']\n",
        "    demo_trajs.append(demo_dict['trajectory'])\n",
        "demo_trajs_preproc = magical.preprocess_demos_with_wrapper(demo_trajs, orig_env_name, preproc_name=preproc_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AiEV5Nr3jx7x"
      },
      "outputs": [],
      "source": [
        "# Build dataset in the format required by imitation. Note that traj.obs contains the final observation after the last\n",
        "# action, so we drop the last observation when concatenating trajectories.\n",
        "all_obs = np.concatenate([traj.obs[:-1] for traj in demo_trajs_preproc], axis=0)\n",
        "all_acts = np.concatenate([traj.acts for traj in demo_trajs_preproc], axis=0)\n",
        "dataset = il_types.TransitionsMinimal(obs=all_obs, acts=all_acts, infos=[{}] * len(all_obs))\n",
        "data_loader = th_data.DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=il_types.transitions_collate_fn)\n",
        "augmenter = il_augment.StandardAugmentations.from_string_spec(\n",
        "       'rotate,translate,noise', stack_color_space=il_augment.ColorSpace.RGB)\n",
        "bc_trainer = BC(\n",
        "    observation_space=env.observation_space,\n",
        "    action_space=env.action_space,\n",
        "    policy_class=sb3_pols.ActorCriticCnnPolicy,\n",
        "    policy_kwargs=dict(features_extractor_class=MAGICALNet),\n",
        "    expert_data=data_loader,\n",
        "    augmentation_fn=augmenter,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n2i3K1Fv_DSN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch: 0/500  epoch: 0:   0%|          | 0/500 [00:00<?, ?it/s]/home/lucaianniello/miniconda3/envs/magical/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:223: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
            "batch: 0/500  epoch: 0:   0%|          | 0/500 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'stable_baselines3.common.logger' has no attribute 'record_mean'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# try training for longer (e.g. 15,000 batches) to get better performance\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbc_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/magical/lib/python3.8/site-packages/imitation/algorithms/bc.py:398\u001b[0m, in \u001b[0;36mBC.train\u001b[0;34m(self, n_epochs, n_batches, on_epoch_end, log_interval)\u001b[0m\n\u001b[1;32m    395\u001b[0m stats_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_tensor)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m stats_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 398\u001b[0m     \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_mean\u001b[49m(k, v)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_num \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    400\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdump(batch_num)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'stable_baselines3.common.logger' has no attribute 'record_mean'"
          ]
        }
      ],
      "source": [
        "# try training for longer (e.g. 15,000 batches) to get better performance\n",
        "bc_trainer.train(n_batches=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1BsgA6ZwP7G"
      },
      "source": [
        "## Evaluating the policy and rendering a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umG_LZNGCO9y"
      },
      "outputs": [],
      "source": [
        "eval_protocol = ImitationEvaluationProtocol(\n",
        "    policy=bc_trainer.policy,\n",
        "    run_description=f\"notebook-demo-{env_name}\",\n",
        "    demo_env_name=env_name,\n",
        "    # number of rollouts per environment\n",
        "    # (small so rollouts are fast)\n",
        "    n_rollouts=15)\n",
        "eval_result = eval_protocol.do_eval(verbose=True)\n",
        "eval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP45aH-pseKI"
      },
      "outputs": [],
      "source": [
        "video = create_policy_video(bc_trainer.policy, env_name)\n",
        "display.display(video)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "demo-notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "magical",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
